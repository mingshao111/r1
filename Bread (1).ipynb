{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/n0362948/desktop/Bread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "intellicron_prequals=pd.read_csv('/Users/n0362948/desktop/Bread/intellicron_prequals.csv')\n",
    "prequals=pd.read_csv('/Users/n0362948/desktop/Bread/prequals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intellicron_prequals['group']='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min=intellicron_prequals['assignment_date'].min()\n",
    "date_max=intellicron_prequals['assignment_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp=pd.merge(prequals,intellicron_prequals,how='left', on='prequal_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp['dummy']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group(row):\n",
    "    if row['group']=='test': \n",
    "        return 'test'\n",
    "    else:\n",
    "        return 'control'\n",
    "    \n",
    "temp['group']=temp.apply(group, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=temp.loc[(temp4['prequal_date']<=date_max) & (temp['prequal_date']>=date_min)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_split=split[['prequal_id','checkout_id','prequal_date','completed_prequal','approved','assignment_date','group','dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18185, 8),\n",
       " Index(['prequal_id', 'checkout_id', 'prequal_date', 'completed_prequal',\n",
       "        'approved', 'assignment_date', 'group', 'dummy'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_split.shape, clean_split.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>completed_prequal</th>\n",
       "      <th>approved</th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>control</th>\n",
       "      <td>5026</td>\n",
       "      <td>3371</td>\n",
       "      <td>9690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>4658</td>\n",
       "      <td>3088</td>\n",
       "      <td>8495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         completed_prequal  approved  dummy\n",
       "group                                      \n",
       "control               5026      3371   9690\n",
       "test                  4658      3088   8495"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_split[['completed_prequal', 'approved',  'group', 'dummy']].groupby('group').agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "summary=clean_split.pivot_table(values='completed_prequal', index='group', aggfunc=np.sum)\n",
    "summary['total']=clean_split.pivot_table(values='completed_prequal', index='group', aggfunc=lambda x:len(x))\n",
    "summary['completion_prequal_rate']=clean_split.pivot_table(values='completed_prequal', index='group')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>completed_prequal</th>\n",
       "      <th>total</th>\n",
       "      <th>completion_prequal_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>control</td>\n",
       "      <td>5026</td>\n",
       "      <td>9690</td>\n",
       "      <td>0.518679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>4658</td>\n",
       "      <td>8495</td>\n",
       "      <td>0.548323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     group  completed_prequal  total  completion_prequal_rate\n",
       "0  control               5026   9690                 0.518679\n",
       "1     test               4658   8495                 0.548323"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prop_test(convert_control, size_control, convert_test, size_test):\n",
    "  \n",
    "    p_a = convert_control / size_control\n",
    "    p_b = convert_test / size_test\n",
    "    p_pooled = (convert_control + convert_test) / (size_control + size_test)\n",
    "    var = p_pooled * (1 - p_pooled) * (1 / size_control + 1 / size_test)\n",
    "    zscore = np.abs(p_b - p_a) / np.sqrt(var)\n",
    "    one_side = 1 - stats.norm(loc = 0, scale = 1).cdf(zscore)\n",
    "    pvalue = one_side * 2\n",
    "    return zscore, pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zscore = 3.997, pvalue = 0.000064\n"
     ]
    }
   ],
   "source": [
    "### this is data for completed prequal out of all test data--> to calculate p value\n",
    "\n",
    "convert_control = 5026\n",
    "size_control = 9690\n",
    "convert_test = 4658\n",
    "size_test = 8495\n",
    "\n",
    "zscore, pvalue = prop_test(convert_control, size_control, convert_test, size_test)\n",
    "print('zscore = {:.3f}, pvalue = {:.6f}'.format(zscore, pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(convert_control, size_control, convert_test, size_test, significance = 0.05):\n",
    "    \"\"\"\n",
    "    A/B test for two proportions;\n",
    "    given a success a trial size of group A and B compute\n",
    "    its confidence interval;\n",
    "    resulting confidence interval matches R's prop.test function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    success_a, success_b : int\n",
    "        Number of successes in each group\n",
    "        \n",
    "    size_a, size_b : int\n",
    "        Size, or number of observations in each group\n",
    "        \n",
    "    significance : float, default 0.05\n",
    "        Often denoted as alpha. Governs the chance of a false positive.\n",
    "        A significance level of 0.05 means that there is a 5% chance of\n",
    "        a false positive. In other words, our confidence level is\n",
    "        1 - 0.05 = 0.95\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    prop_diff : float\n",
    "        Difference between the two proportion\n",
    "    \n",
    "    confint : 1d ndarray\n",
    "        Confidence interval of the two proportion test\n",
    "    \"\"\"\n",
    "    p_a = convert_control / size_control\n",
    "    p_b = convert_test / size_test\n",
    "    var = p_a * (1 - p_a) / convert_control + p_b * (1 - p_b) / size_test\n",
    "    se = np.sqrt(var)\n",
    "    \n",
    "    # z critical value\n",
    "    confidence = 1 - significance\n",
    "    z = stats.norm(loc = 0, scale = 1).ppf(confidence + significance / 2)\n",
    "\n",
    "    # standard formula for the confidence interval\n",
    "    # point-estimtate +- z * standard-error\n",
    "    prop_diff = p_b - p_a\n",
    "    confint = prop_diff + np.array([-1, 1]) * z * se\n",
    "    return prop_diff, confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate difference: 0.029643492104564628\n",
      "confidence interval: [ 0.01224213  0.04704485]\n"
     ]
    }
   ],
   "source": [
    "### this is data for completed prequal out of all test data--> to calculate confidence interval\n",
    "\n",
    "prop_diff, confint = confidence_interval(convert_control, size_control, convert_test, size_test)\n",
    "print('estimate difference:', prop_diff)\n",
    "print('confidence interval:', confint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "summary_2=clean_split.pivot_table(values='completed_prequal', index='group', aggfunc=np.sum)\n",
    "summary_2['total']=clean_split.pivot_table(values='completed_prequal', index='group', aggfunc=lambda x:len(x))\n",
    "summary_['completion_prequal_rate']=clean_split.pivot_table(values='completed_prequal', index='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zscore = 2.196, pvalue = 0.028060\n"
     ]
    }
   ],
   "source": [
    "### this is data for approved out of all test data--> to calculate p value and confidence interval \n",
    "\n",
    "convert_control2 = 3371\n",
    "size_control2 = 9690\n",
    "convert_test2 = 3088\n",
    "size_test2 = 8495\n",
    "\n",
    "zscore, pvalue = prop_test(convert_control2, size_control2, convert_test2, size_test2)\n",
    "print('zscore = {:.3f}, pvalue = {:.6f}'.format(zscore, pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate difference: 0.015623528925835684\n",
      "confidence interval: [-0.00343291  0.03467996]\n"
     ]
    }
   ],
   "source": [
    "prop_diff, confint = confidence_interval(convert_control2, size_control2, convert_test2, size_test2)\n",
    "print('estimate difference:', prop_diff)\n",
    "print('confidence interval:', confint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
